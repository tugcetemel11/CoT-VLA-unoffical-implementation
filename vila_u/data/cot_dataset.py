# -*- coding: utf-8 -*-
"""cot-dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ic0EoM0uxU3dXQoceLQWRz-07ua1r3jO
"""

from vila_u.constants import IMAGE_TOKEN_INDEX
from vila_u.mm_utils import tokenizer_image_token

class CoTVLADataset(Dataset):
    def __init__(self, json_path):
        with open(json_path) as f:
            self.samples = json.load(f)

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        s = self.samples[idx]

        cot = "\n".join(s["visual_cot"])
        action = "\n".join(s["action"])

        # ---------- PROMPT ) ----------
        conv = conv_templates["vicuna_v1"].copy()
        conv.append_message(
            conv.roles[0],
            f"<image>\n{s['instruction']}"
        )
        conv.append_message(conv.roles[1], None)
        prompt = conv.get_prompt()

        # ---------- TARGET ----------
        target = (
            "<cot>\n"
            f"{cot}\n"
            "</cot>\n"
            "<action>\n"
            f"{action}\n"
            "</action>"
        )

        full_text = prompt + target

        input_ids = tokenizer_image_token(
            full_text,
            tokenizer,
            IMAGE_TOKEN_INDEX,
            return_tensors="pt"
        ).squeeze(0)

        attention_mask = input_ids.ne(tokenizer.pad_token_id)

        labels = input_ids.clone()
        labels[:] = -100  # mask everything

        # Unmask from <cot> onward
        cot_token_id = tokenizer.convert_tokens_to_ids("<cot>")
        cot_pos = (input_ids == cot_token_id).nonzero(as_tuple=True)[0]

        if len(cot_pos) > 0:
            labels[cot_pos[0]:] = input_ids[cot_pos[0]:]

        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": labels
        }